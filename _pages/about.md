---
permalink: /
title: "Biophysics in Network Science, Molecular Evolution, Stochastic Processes, and Optimization"
excerpt: "I am a researcher with a recent completion of my Ph.D at Rutgers University in Physics & Astronomy studying various topics in the field of biological physics."
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
The field of biophysics covers a vast umbrella of topics and subfields. During my graduate career at Rutgers University I delved into several of these subfields in an attempt to understand the workings of living matter. My approach has been primarily through the avenues of complex network science and inference, molecular evolution and population genetics modeling, the study of stochastic processes, and objective function optimization. The following sections overview some of the work I have completed in the last few years on these topics.

Complex Networks
====

The instances of [complex networks](https://en.wikipedia.org/wiki/Complex_network) in the life sciences are numerous. Examples include protein interaction networks, neural networks, networks of predator-prey interactions, etc. In my own research, I have focused on weighted, undirected networks (i.e. the edge weights $w_{ji} = w_{ij}$ are symmetric between nodes $i$ and $j$), the main contribution being a general Bayesian theoretical formalism for generating estimators of global network properties given  only a very small sample of the entire system, $<1\%$. The data acquisition method I have studied for this resarch is [random walk](https://en.wikipedia.org/wiki/Random_walk) sampling: after each network node is sampled, a random neighbor is chosen from the links directly connected to that node as the next sample, and this process is continued until the number of desired samples is attained.  

<div style="text-align:center"><img src ="/images/infin_network.png" width='525'/></div>

As an example of an estimator generated by our Bayesian formalism, the estimator for the network-wide average connectivity, denoted $\langle k \rangle\equiv \sum_i k_i / N$ for a network with $N$ nodes, is given by

\begin{aligned}
\widehat{\langle k \rangle} = \frac{\ell}{\sum_k \mathcal{K}_k / k},
\end{aligned}

when $\ell\ll N$ nodes have been sampled, and $\mathcal{K}_k$ nodes with connectivity $k$ have been visited (this includes repeated visits to the same node.) This formula, derived through this Bayesian formalism, looks very odd when compared to what is typically done when nodes are sampled uniformly,

\begin{aligned}
\widehat{\langle k \rangle} = \frac{\sum_k k \mathcal{K}_k}{\ell},
\end{aligned}

and yet proves to be a much better estimator!  

This formalism also establishes a rigorous error analysis which yields a high probability range for these estimators. For this particular quantity, this error range falls off as $\sim 1/\sqrt{\ell},$ independent of the network size! This estimator captures the true value long before the diffusive process of the random walk reaches equilibrium. For further detail and other examples of network property estimators that this formalism yields, including one for the full network size, see [this paper](https://willowbk.github.io/publication/RapidBayesianInference).

Epidemiology
====
A clear example of a complex network in the life sciences is the network of geographical regions through which a pathogen might spread. This could be the network of all major cities in the world, with dynamical links representing traffic between each city, or the network of all major airports, etc. Such a model has been developed in [this paper](http://www.pnas.org/content/106/40/16897.short) where it has been shown that there is a critical value for the node infection probability upon pathogen exposure, $\beta$, which is connected to the average network connectivity by

\begin{aligned}
\beta_\text{critical} \propto \langle k \rangle,
\end{aligned}

above which there can be a sustained epidemic outbreak in the system. This is a valuable quantity to estimate, and is a prime example of a network property which is rapidly attained when employing random walk sampling instead of uniform sampling.

Although the infection process itself is dynamic as the disease spreads, random walk sampling is indeed applicable given a "rapid-enough" sampling process. This network has been sampled both in [this poster](https://willowbk.github.io/talks/NetworkInferencePoster) and [this paper](https://willowbk.github.io/publication/RapidBayesianInference) and the fraction of nodes (cities) infected, $\rho(t)$, accurately estimated and tracked as a function of time. This then suggests an alternative method for tracking the course of epidemic diseases, such as the recent Ebola outbreak.

Cancer Research
====
Although in its early stages, I have begun a project to use the network sampling methodology to determine which groups of genes are responsible for the metabolism of cancerous cells. More to come on this topic in the near future!

Molecular Evolution 
====
Outside the realm of complex network science, much of my graduate career has been spent modeling life processes on both the molecular and population levels. My main objective has been the development of a biophysical model for the computational prediction of genomic features such as the [codon usage bias](https://en.wikipedia.org/wiki/Codon_usage_bias).

Predicting the Codon Usage Bias
====
The central dogma of biology has triplets of nucleotides called codons translated into amino acids for the production of all proteins. As there are far more codons than amino acids, this translation code is necessarily degenerate with as many as six codons translated into a single amino acid. With the functionality of proteins determined by their amino acid sequences, the choice of synonymous codon should be random or determined solely through mutational rates. However, this is not what is observed in coding sequence data. The unexpected enrichment in the usage of certain synonymous codons is known as the codon bias.

A proposed explanation for this bias is that certain codons are more efficiently translated by the ribosome than others. Efficiency can be characterized as a balance between translation speed and accuracy: a particular codon may be more rapidly translated due to a higher concentration in the tRNA pool, but may also result in more translation errors. These translation errors are the direct result of the Wobble Hypothesis which states that each codon can be recognized by other-than-cognate tRNA species with each mispairing only occuring in the 3' nucleotide position. 

<div style="text-align:center"><img src ="/images/wobble.png" width='300'/>  </div>  
$~$                                                              
The above image of the mechanics of a ribosome during translation in <i>Escherichia coli</i> shows how wobble pairing can be responsible for an amino acid swap (Isoleucine to Methionine when anticodon CAU pairs with codon AUA) during protein production on a [thrA gene](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC350143) transcript. Both of these tRNA species shown are present in <i>E. coli</i> K-12 MG1655 cells and so this mispairing can indeed occur. 

For this project the fitness of an organism is modeled as a function of codon translation efficiency. With reasonable biophysical parameters the codon bias is well characterized as a balance between mutation and selection on translation speed and accuracy when the Wobble Hypothesis is included in sufficient detail. Additionally the effects of the topology of the network formed by single-point mutations between codons significantly contribute to the codon bias. For further details on this project see the section on [presentations and posters](https://willowbk.github.io/talks), and [this paper](https://willowbk.github.io/publication/InferringBiophysicalModels).


Objective Function Optimization
====
Evolutionary biology is ripe with instances of optimized physiology and behaviors. In the field of computer science, many modern optimization algorithms designed to find the extremum of some objective function are based on, or inspired by, natural phenomena. Examples include simulated annealing; guided by the laws of statistical mechanics, and genetic algorithms; structured to mimic evolutionary processes. These algorithms often put faith in some underlying principle. An alternative approach could be to develop a strategy-based algorithm which makes intelligent choices based on the local information of the objective function landscape, and updates its decisions after considering the history of the optimization.  

A strategy-based algorithm has been employed in the codon bias project described previously, and a general formulation is in production. Below is an animation of one of the early algorithms learning to rotate a cluster of rigid mass points into the first octant.

<div style="text-align:center"><img src="/images/Rig_Rot_D3_N100.gif" width="500"/> </div>
<!---
A data-driven personal website
======
just be sure to save the markdown files! Finally, you can also write scripts that process the structured data on the site, such as [this one](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb) that analyzes metadata in pages about talks to display [a map of every location you've given a talk](https://academicpages.github.io/talkmap.html).

Getting started
======
1. Set site-wide configuration and create content & metadata (see below -- also see [this set of diffs](http://archive.is/3TPas) showing what files were changed to set up [an example site](https://getorg-testacct.github.io) for a user with the username "getorg-testacct")
1. Upload any files (like PDFs, .zip files, etc.) to the files/ directory. They will appear at https://[your GitHub username].github.io/files/example.pdf.  
1. Check status by going to the repository settings, in the "GitHub pages" section

Site-wide configuration
------
The main configuration file for the site is in the base directory in [_config.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_config.yml), which defines the content in the sidebars and other site-wide features. You will need to replace the default variables with ones about yourself and your site's github repository. The configuration file for the top menu is in [_data/navigation.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_data/navigation.yml). For example, if you don't have a portfolio or blog posts, you can remove those items from that navigation.yml file to remove them from the header. 

Create content & metadata
------
For site content, there is one markdown file for each type of content, which are stored in directories like _publications, _talks, _posts, _teaching, or _pages. For example, each talk is a markdown file in the [_talks directory](https://github.com/academicpages/academicpages.github.io/tree/master/_talks). At the top of each markdown file is structured data in YAML about the talk, which the theme will parse to do lots of cool stuff. The same structured data about a talk is used to generate the list of talks on the [Talks page](https://academicpages.github.io/talks), each [individual page](https://academicpages.github.io/talks/2012-03-01-talk-1) for specific talks, the talks section for the [CV page](https://academicpages.github.io/cv), and the [map of places you've given a talk](https://academicpages.github.io/talkmap.html) (if you run this [python file](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.py) or [Jupyter notebook](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb), which creates the HTML for the map based on the contents of the _talks directory).

**Markdown generator**

I have also created [a set of Jupyter notebooks](https://github.com/academicpages/academicpages.github.io/tree/master/markdown_generator
) that converts a CSV containing structured data about talks or presentations into individual markdown files that will be properly formatted for the academicpages template. The sample CSVs in that directory are the ones I used to create my own personal website at stuartgeiger.com. My usual workflow is that I keep a spreadsheet of my publications and talks, then run the code in these notebooks to generate the markdown files, then commit and push them to the GitHub repository.

How to edit your site's GitHub repository
------
Many people use a git client to create files on their local computer and then push them to GitHub's servers. If you are not familiar with git, you can directly edit these configuration and markdown files directly in the github.com interface. Navigate to a file (like [this one](https://github.com/academicpages/academicpages.github.io/blob/master/_talks/2012-03-01-talk-1.md) and click the pencil icon in the top right of the content preview (to the right of the "Raw | Blame | History" buttons). You can delete a file by clicking the trashcan icon to the right of the pencil icon. You can also create new files or upload files by navigating to a directory and clicking the "Create new file" or "Upload files" buttons. 

Example: editing a markdown file for a talk
![Editing a markdown file for a talk](/images/editing-talk.png)

For more info
------
More info about configuring academicpages can be found in [the guide](https://academicpages.github.io/markdown/). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful.
--->
